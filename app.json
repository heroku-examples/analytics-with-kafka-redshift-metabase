{
  "name": "Example Product/User Analytics System Using Apache Kafka, AWS RedShift, and Metabase",
  "description": "This is an example of a system that captures a large stream of product usage data, or events, and provides both real-time data visualization and SQL-based data analytics.",
  "keywords": [
    "heroku",
    "aws-redshift",
    "metabase",
    "kafka",
    "data analytics",
    "data visualization"
  ],
  "repository": "https://github.com/heroku-examples/analytics-with-kafka-redshift-metabase",
  "success_url": "/",
  "env": {
    "USE_DB": {
      "description": "Use AWS Redshift or Heroku Postres. Can be 'redshift' or 'heroku'.",
      "value": "redshift"
    },
    "AWS_ACCESS_KEY_ID": {
      "description": "AWS access key used by RedShift to access fixture data in S3"
    },
    "AWS_SECRET_ACCESS_KEY": {
      "description": "AWS secret access key used by RedShift to access fixture data in S3"
    },
    "ADMIN_PASSWORD": {
      "description": "Password to use Demo Admin functionality. Default is 'supersecret'."
    },
    "AWS_DATABASE_URL": {
      "description": "Connection string to RedShift database (e.g. postgres://username:password@my-redshift-cluster.abcdef123456.us-east-1.redshift.amazonaws.com:5439/db_name)"
    },
    "FIXTURE_DATA_S3": {
      "description": "S3 path to CSV of fixture data to load into Redshift before starting data stream through Kafka. Leave the default unless you have a reason to change it.",
      "value": "s3://aws-heroku-integration-demo/fixture.csv"
    },
    "KAFKA_PREFIX": {
      "description": "Prefix for Kafka topics. Include a trailing seperator character if you expect one.",
      "required": false
    },
    "KAFKA_TOPIC": {
      "description": "Kafka topic name. Leave the default unless you have a reason to change it.",
      "value": "ecommerce-logs",
      "required": true
    },
    "KAFKA_CMD_TOPIC": {
      "description": "Kafka topic name for audience cmds. Leave the default unless you have a reason to change it.",
      "value": "audience-cmds",
      "required": true
    },
    "KAFKA_WEIGHT_TOPIC": {
      "description": "Kafka topic name for category weight updates. Leave the default unless you have a reason to change it.",
      "value": "weight-updates",
      "required": true
    },
    "KAFKA_QUEUE_TOPIC": {
      "description": "Kafka topic name for queue length updates. Leave the default unless you have a reason to change it.",
      "value": "queue-length",
      "required": true
    },
    "KAFKA_QUEUE_WORKER": {
      "description": "Kafka topic name for queue worker updates. Leave the default unless you have a reason to change it.",
      "value": "queue-worker",
      "required": true
    },
    "KAFKA_CONSUMER_GROUP": {
      "description": "Kafka consumer group name that is used by `redshift_batch` process type. Leave the default unless you have a reason to change it.",
      "value": "redshift-batch",
      "required": true
    }
  },
  "formation": {
    "web": {
      "quantity": 1
    },
    "redshift_batch": {
      "quantity": 1
    }
  },
  "addons": ["heroku-kafka:basic-0"]
}
